{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eab0201e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AppID': Value('int64'), 'Name': Value('string'), 'Release date': Value('string'), 'Estimated owners': Value('string'), 'Peak CCU': Value('int64'), 'Required age': Value('int64'), 'Price': Value('float64'), 'DLC count': Value('int64'), 'About the game': Value('string'), 'Supported languages': Value('string'), 'Full audio languages': Value('string'), 'Reviews': Value('string'), 'Header image': Value('string'), 'Website': Value('string'), 'Support url': Value('string'), 'Support email': Value('string'), 'Windows': Value('bool'), 'Mac': Value('bool'), 'Linux': Value('bool'), 'Metacritic score': Value('int64'), 'Metacritic url': Value('string'), 'User score': Value('int64'), 'Positive': Value('int64'), 'Negative': Value('int64'), 'Score rank': Value('float64'), 'Achievements': Value('int64'), 'Recommendations': Value('int64'), 'Notes': Value('string'), 'Average playtime forever': Value('int64'), 'Average playtime two weeks': Value('int64'), 'Median playtime forever': Value('int64'), 'Median playtime two weeks': Value('int64'), 'Developers': Value('string'), 'Publishers': Value('string'), 'Categories': Value('string'), 'Genres': Value('string'), 'Tags': Value('string'), 'Screenshots': Value('string'), 'Movies': Value('string')}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"FronkonGames/steam-games-dataset\")\n",
    "\n",
    "# get columns names and types\n",
    "columns = dataset[\"train\"].features\n",
    "print(columns)\n",
    "\n",
    "columns_to_keep = [\"Name\", \"Windows\", \"Linux\", \"Mac\", \"About the game\", \"Supported languages\", \"Price\"]\n",
    "\n",
    "N = 40000\n",
    "dataset = dataset[\"train\"].select_columns(columns_to_keep).select(range(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c400e289",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30244/3426781059.py:7: SAWarning: This declarative base already contains a class with the same class name and module name as __main__.Games, and will be replaced in the string-lookup table.\n",
      "  class Games(Base):\n"
     ]
    }
   ],
   "source": [
    "from database import engine, Base\n",
    "from sqlalchemy import Integer, Float, Boolean, String\n",
    "from sqlalchemy.orm import Mapped, mapped_column\n",
    "from pgvector.sqlalchemy import Vector\n",
    "\n",
    "\n",
    "class Games(Base):\n",
    "    __tablename__ = \"games\"\n",
    "    __table_args__ = {'extend_existing': True}\n",
    "    \n",
    "    # the vector size produced by the model taken from documentation https://huggingface.co/sentence-transformers/distiluse-base-multilingual-cased-v2\n",
    "    VECTOR_LENGTH = 512\n",
    "        \n",
    "    id: Mapped[int] = mapped_column(Integer, primary_key=True)\n",
    "    name: Mapped[str] = mapped_column(String(256))\n",
    "    description: Mapped[str] = mapped_column(String(4096))\n",
    "    windows: Mapped[bool] = mapped_column(Boolean)\n",
    "    linux: Mapped[bool] = mapped_column(Boolean)\n",
    "    mac: Mapped[bool] = mapped_column(Boolean)\n",
    "    price: Mapped[float] = mapped_column(Float)\n",
    "    game_description_embedding = mapped_column(Vector(VECTOR_LENGTH))\n",
    "\n",
    "#Base.metadata.drop_all(engine)\n",
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b641d1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "checkpoint = \"distiluse-base-multilingual-cased-v2\"\n",
    "model = SentenceTransformer(checkpoint)\n",
    "\n",
    "\n",
    "def generate_embeddings(text: str) -> list[float]:\n",
    "    return model.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc66909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sqlalchemy.orm import Session\n",
    "\n",
    "def insert_games(engine, dataset):\n",
    "    with tqdm(total=len(dataset)) as pbar:\n",
    "        for i, game in enumerate(dataset):\n",
    "            game_description = game[\"About the game\"] or \"\"\n",
    "            game_embedding = generate_embeddings(game_description)\n",
    "            name, windows, linux, mac, price = game[\"Name\"], game[\"Windows\"], game[\"Linux\"], game[\"Mac\"], game[\"Price\"]\n",
    "            if name and windows and linux and mac and price and game_description:\n",
    "                game = Games(\n",
    "                    name=game[\"Name\"], \n",
    "                    description=game_description[0:4096],\n",
    "                    windows=game[\"Windows\"], \n",
    "                    linux=game[\"Linux\"], \n",
    "                    mac=game[\"Mac\"], \n",
    "                    price=game[\"Price\"], \n",
    "                    game_description_embedding=game_embedding\n",
    "                )\n",
    "                with Session(engine) as session:\n",
    "                    session.add(game)\n",
    "                    session.commit()\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4cc4598f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40000/40000 [02:46<00:00, 240.15it/s]\n"
     ]
    }
   ],
   "source": [
    "insert_games(engine, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cce966bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import sqlalchemy\n",
    "from sqlalchemy import select\n",
    "\n",
    "def find_game(\n",
    "    engine: sqlalchemy.Engine, \n",
    "    game_description: str, \n",
    "    windows: Optional[bool] = None, \n",
    "    linux: Optional[bool] = None,\n",
    "    mac: Optional[bool] = None,\n",
    "    price: Optional[int] = None\n",
    "):\n",
    "    with Session(engine) as session:\n",
    "        game_embedding = generate_embeddings(game_description)\n",
    "    \n",
    "        query = (\n",
    "            select(Games)\n",
    "            .order_by(Games.game_description_embedding.cosine_distance(game_embedding))\n",
    "        )\n",
    "        \n",
    "        if price:\n",
    "            query = query.filter(Games.price <= price)\n",
    "        if windows:\n",
    "            query = query.filter(Games.windows == True)\n",
    "        if linux:\n",
    "            query = query.filter(Games.linux == True)\n",
    "        if mac:\n",
    "            query = query.filter(Games.mac == True)\n",
    "        \n",
    "        result = session.execute(query, execution_options={\"prebuffer_rows\": True})\n",
    "        game = result.scalars().first()\n",
    "        \n",
    "        return game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4778b395",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function Client.__del__ at 0x7eaf9e6536a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jacek-tyszkiewicz/lab_4MLProject/.venv/lib/python3.11/site-packages/google/genai/client.py\", line 400, in __del__\n",
      "    self.close()\n",
      "  File \"/home/jacek-tyszkiewicz/lab_4MLProject/.venv/lib/python3.11/site-packages/google/genai/client.py\", line 386, in close\n",
      "    self._api_client.close()\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Client' object has no attribute '_api_client'\n",
      "Exception ignored in: <function Client.__del__ at 0x7eaf9e6536a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jacek-tyszkiewicz/lab_4MLProject/.venv/lib/python3.11/site-packages/google/genai/client.py\", line 400, in __del__\n",
      "    self.close()\n",
      "  File \"/home/jacek-tyszkiewicz/lab_4MLProject/.venv/lib/python3.11/site-packages/google/genai/client.py\", line 386, in close\n",
      "    self._api_client.close()\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Client' object has no attribute '_api_client'\n",
      "Exception ignored in: <function Client.__del__ at 0x7eaf9e6536a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jacek-tyszkiewicz/lab_4MLProject/.venv/lib/python3.11/site-packages/google/genai/client.py\", line 400, in __del__\n",
      "    self.close()\n",
      "  File \"/home/jacek-tyszkiewicz/lab_4MLProject/.venv/lib/python3.11/site-packages/google/genai/client.py\", line 386, in close\n",
      "    self._api_client.close()\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Client' object has no attribute '_api_client'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game: Ultimate Spider Hero\n",
      "Description: Ultimate Spider Hero game was designed for real heroes! Your mission is to help poor residents of the Metropolis and to save them from the terrible monsters. Move forward to fight your enemies and try not to fall! Features: Simple and addictive gameplay Nice graphics Awesome Ultimate Spider Hero Countless Steam achievements for you to collect! Compatibility with multiple major platforms (Windows, Mac, Linux, SteamOS) Make your way through the endless labyrinths of long, confusing city streets together with your favorite hero from countless movies and cartoons! Although this may look simple enough, things are not as easy as they seem. You will have to learn how to cling into houses properly using your web, otherwise you will fall to your demise. If you manage to do so - you will become a real superhero, armed with elusiveness, agility and speed and the ability to tirelessly swing across the rooftops and between the huge skyscrapers this urban landscape has to offer in this thrilling game of a super spider. It's fun, the visuals are magnificent and the controls are simple!\n",
      "Game: 3D PUZZLE - Modern House\n",
      "Description: Collect a 3D puzzle, transferring things to the right places to create a beautiful house. You need to go to the item, take it by pressing the left mouse button and take the item to the desired location marked in green. If you brought the correct item, it will snap into place and you will receive leaderboard points and achievements for this. Collect as much substance as possible as quickly as possible to get more points for the leaderboard. If you brought the wrong item, you can throw it away, it will return to the starting location so that you can pick it up again.\n"
     ]
    }
   ],
   "source": [
    "game = find_game(engine, \"This is a game about a hero who saves the world\", price=10)\n",
    "print(f\"Game: {game.name}\")\n",
    "print(f\"Description: {game.description}\")\n",
    "\n",
    "game = find_game(engine, game_description=\"Home decorating\", price=20)\n",
    "print(f\"Game: {game.name}\")\n",
    "print(f\"Description: {game.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "adc70b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game: 3D PUZZLE - Old House\n",
      "Description: Collect a 3D puzzle, transferring things to the right places to create a beautiful house. You need to go to the item, take it by pressing the left mouse button and take the item to the desired location marked in green. If you brought the correct item, it will snap into place and you will receive leaderboard points and achievements for this. Collect as much substance as possible as quickly as possible to get more points for the leaderboard. If you brought the wrong item, you can throw it away, it will return to the starting location so that you can pick it up again.\n"
     ]
    }
   ],
   "source": [
    "game = find_game(engine, game_description=\"Home decorating\", mac=True, price=5)\n",
    "print(f\"Game: {game.name}\")\n",
    "print(f\"Description: {game.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbe8a29",
   "metadata": {},
   "source": [
    "### RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "60e7b023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "host = \"localhost\"\n",
    "port = \"19530\"\n",
    "\n",
    "milvus_client = MilvusClient(\n",
    "    host=host,\n",
    "    port=port\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85cde4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import FieldSchema, DataType, CollectionSchema\n",
    "\n",
    "VECTOR_LENGTH = 768 \n",
    "\n",
    "id_field = FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, description=\"Primary id\")\n",
    "text = FieldSchema(name=\"text\", dtype=DataType.VARCHAR, max_length=4096, description=\"Page text\")\n",
    "embedding_text = FieldSchema(\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=VECTOR_LENGTH, description=\"Embedded text\")\n",
    "\n",
    "fields = [id_field, text, embedding_text]\n",
    "\n",
    "schema = CollectionSchema(fields=fields, auto_id=True, enable_dynamic_field=True, description=\"RAG Texts collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d01f3fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rag_texts_and_embeddings']\n",
      "{'collection_name': 'rag_texts_and_embeddings', 'auto_id': True, 'num_shards': 1, 'description': 'RAG Texts collection', 'fields': [{'field_id': 100, 'name': 'id', 'description': 'Primary id', 'type': <DataType.INT64: 5>, 'params': {}, 'auto_id': True, 'is_primary': True}, {'field_id': 101, 'name': 'text', 'description': 'Page text', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 4096}}, {'field_id': 102, 'name': 'embedding', 'description': 'Embedded text', 'type': <DataType.FLOAT_VECTOR: 101>, 'params': {'dim': 768}}], 'functions': [], 'aliases': [], 'collection_id': 462201857833960672, 'consistency_level': 2, 'properties': {}, 'num_partitions': 1, 'enable_dynamic_field': True, 'created_timestamp': 462201922699395077}\n"
     ]
    }
   ],
   "source": [
    "COLLECTION_NAME = \"rag_texts_and_embeddings\"\n",
    "\n",
    "milvus_client.create_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    schema=schema\n",
    ")\n",
    "\n",
    "index_params = milvus_client.prepare_index_params()\n",
    "\n",
    "index_params.add_index(\n",
    "    field_name=\"embedding\", \n",
    "    index_type=\"HNSW\",\n",
    "    metric_type=\"L2\",\n",
    "    params={\"M\": 4, \"efConstruction\": 64}  # lower values for speed\n",
    ") \n",
    "\n",
    "milvus_client.create_index(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    index_params=index_params\n",
    ")\n",
    "\n",
    "# checkout our collection\n",
    "print(milvus_client.list_collections())\n",
    "\n",
    "# describe our collection\n",
    "print(milvus_client.describe_collection(COLLECTION_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6bd57a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data source and destination\n",
    "## the document origin destination from which document will be downloaded \n",
    "pdf_url = \"https://www.iab.org.pl/wp-content/uploads/2024/04/Przewodnik-po-sztucznej-inteligencji-2024_IAB-Polska.pdf\"\n",
    "\n",
    "## local destination of the document\n",
    "file_name = \"Przewodnik-po-sztucznej-inteligencji-2024_IAB-Polska.pdf\"\n",
    "\n",
    "## local destination of the processed document \n",
    "file_json = \"Przewodnik-po-sztucznej-inteligencji-2024_IAB-Polska.json\"\n",
    "\n",
    "## local destination of the embedded pages of the document\n",
    "embeddings_json = \"Przewodnik-po-sztucznej-inteligencji-2024_IAB-Polska-Embeddings.json\"\n",
    "\n",
    "## local destination of all above local required files\n",
    "data_dir = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "033b52e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data\n",
    "import os\n",
    "import requests\n",
    "\n",
    "def download_pdf_data(pdf_url: str, file_name: str) -> None:\n",
    "    response = requests.get(pdf_url, stream=True)\n",
    "    with open(os.path.join(data_dir, file_name), \"wb\") as file:\n",
    "        for block in response.iter_content(chunk_size=1024):\n",
    "            if block:\n",
    "                file.write(block)\n",
    "\n",
    "download_pdf_data(pdf_url, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0c6f9238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "\n",
    "import fitz\n",
    "import json\n",
    "\n",
    "\n",
    "def extract_pdf_text(file_name, file_json):\n",
    "    document = fitz.open(os.path.join(data_dir, file_name))\n",
    "    pages = []\n",
    "\n",
    "    for page_num in range(len(document)):\n",
    "        page = document.load_page(page_num)\n",
    "        page_text = page.get_text()\n",
    "        pages.append({\"page_num\": page_num, \"text\": page_text})\n",
    "\n",
    "    with open(os.path.join(data_dir, file_json), \"w\") as file:\n",
    "        json.dump(pages, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "extract_pdf_text(file_name, file_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce771655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize data\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "def generate_embeddings(file_json, embeddings_json, model):\n",
    "    pages = []\n",
    "    with open(os.path.join(data_dir, file_json), \"r\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    for page in data:\n",
    "        pages.append(page[\"text\"])\n",
    "\n",
    "    embeddings = model.encode(pages)\n",
    "\n",
    "    embeddings_paginated = []\n",
    "    for page_num in range(len(embeddings)):\n",
    "        embeddings_paginated.append({\"page_num\": page_num, \"embedding\": embeddings[page_num].tolist()})\n",
    "\n",
    "    with open(os.path.join(data_dir, embeddings_json), \"w\") as file:\n",
    "        json.dump(embeddings_paginated, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "model_name = \"ipipan/silver-retriever-base-v1.1\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = SentenceTransformer(model_name, device=device)\n",
    "generate_embeddings(file_json, embeddings_json, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1f62533f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_embeddings(file_json, embeddings_json, client=milvus_client):\n",
    "    rows = []\n",
    "    with open(os.path.join(data_dir, file_json), \"r\") as t_f, open(os.path.join(data_dir, embeddings_json), \"r\") as e_f:\n",
    "        text_data, embedding_data = json.load(t_f), json.load(e_f)\n",
    "        text_data =  list(map(lambda d: d[\"text\"], text_data))\n",
    "        embedding_data = list(map(lambda d: d[\"embedding\"], embedding_data))\n",
    "        \n",
    "        for page, (text, embedding) in enumerate(zip(text_data, embedding_data)):\n",
    "            rows.append({\"text\":text, \"embedding\": embedding})\n",
    "\n",
    "    client.insert(collection_name=\"rag_texts_and_embeddings\", data=rows)\n",
    "\n",
    "\n",
    "insert_embeddings(file_json, embeddings_json)\n",
    "\n",
    "# load inserted data into memory\n",
    "milvus_client.load_collection(\"rag_texts_and_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c63e2312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search\n",
    "def search(model, query, client=milvus_client):\n",
    "    embedded_query = model.encode(query).tolist()\n",
    "    result = client.search(\n",
    "        collection_name=\"rag_texts_and_embeddings\", \n",
    "        data=[embedded_query], \n",
    "        limit=1,\n",
    "        search_params={\"metric_type\": \"L2\"},\n",
    "        output_fields=[\"text\"]\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "result = search(model, query=\"Czym jest sztuczna inteligencja\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "914a3304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: [[{'id': 462201857833965911, 'distance': 29.125167846679688, 'entity': {'text': 'Historia powstania\\nsztucznej inteligencji\\n7\\nW języku potocznym „sztuczny\" oznacza to, co\\njest \\nwytworem \\nmającym \\nnaśladować \\ncoś\\nnaturalnego. W takim znaczeniu używamy\\nterminu ,,sztuczny\\'\\', gdy mówimy o sztucznym\\nlodowisku lub oku. Sztuczna inteligencja byłaby\\nczymś (programem, maszyną) symulującym\\ninteligencję naturalną, ludzką.\\nSztuczna inteligencja (AI) to obszar informatyki,\\nktóry skupia się na tworzeniu programów\\nkomputerowych zdolnych do wykonywania\\nzadań, które wymagają ludzkiej inteligencji. \\nTe zadania obejmują rozpoznawanie wzorców,\\nrozumienie języka naturalnego, podejmowanie\\ndecyzji, uczenie się, planowanie i wiele innych.\\nGłównym celem AI jest stworzenie systemów,\\nktóre są zdolne do myślenia i podejmowania\\ndecyzji na sposób przypominający ludzki.\\nHistoria sztucznej inteligencji sięga lat 50. \\nXX wieku, kiedy to powstały pierwsze koncepcje\\ni modele tego, co mogłoby stać się sztuczną\\ninteligencją. Jednym z pionierów był Alan\\nTuring, który sformułował test Turinga, mający\\nna \\ncelu \\nocenę \\nzdolności \\nmaszyny \\ndo\\ninteligentnego \\nzachowania \\nna \\npoziomie\\nludzkim. Jednakże dopiero w latach 80. i 90.\\nnastąpił \\nprawdziwy \\nprzełom \\nw \\ndziedzinie\\nsztucznej \\ninteligencji \\ndzięki \\npostępowi \\nw\\ndziedzinie algorytmów uczenia maszynowego.\\nW wypadku sztucznej inteligencji mamy na\\nuwadze system, który realizowałby niektóre\\nfunkcje \\numysłu \\n– \\nczasami \\nw \\nsposób\\nprzewyższający funkcje naturalne (na przykład,\\naby był wolny od pomyłek przy liczeniu oraz\\ndefektów \\npamięci). \\nInteligencja \\njest \\nwła-\\nściwością umysłu. \\nSkłada się na nią szereg umiejętności, takich jak\\nzdolność do komunikowania, rozwiązywania\\nproblemów, uczenia się i dostosowywania do\\nsytuacji. \\nIstotna \\njest \\njednak \\numiejętność\\nrozumowania.\\nWspółczesne systemy sztucznej inteligencji są\\ninteligentne tylko w ograniczonym obszarze. \\nNa przykład komputer potrafi grać w szachy w\\ntaki \\nsposób, \\nże \\nwygrywa \\nz \\nszachowym\\narcymistrzem. W 1996 r. Deep Blue wygrał jedną\\npartię \\nszachów \\nz \\nGarry \\nKasparowem,\\nprzegrywając cały mecz wynikiem 4:2 (przy\\ndwóch remisach).\\nPóźniej Deep Blue został ulepszony i nie-\\noficjalnie \\nnazwany \\n„Deeper \\nBlue\". \\nZagrał\\nponownie z Kasparowem w maju 1997 roku.\\nMecz \\nskończył \\nsię \\nwynikiem \\n3½:2½ \\ndla\\nkomputera. W ten sposób Deep Blue stał się\\npierwszym systemem komputerowym, który\\nwygrał z aktualnym mistrzem świata w meczu\\nze standardową kontrolą czasu.\\nŹródło: Midjourney – obraz wygenerowany przez AI\\n'}}]]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fb5ca26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google import genai\n",
    "\n",
    "GEMINI_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "gemini_client = genai.Client(api_key=GEMINI_KEY)\n",
    "\n",
    "MODEL = \"gemini-2.0-flash\"\n",
    "\n",
    "def generate_response(prompt: str):\n",
    "    try:\n",
    "        # Send request to Gemini 2.0 Flash API and get the response\n",
    "        response = gemini_client.models.generate_content(\n",
    "            model=MODEL,\n",
    "            contents=prompt,\n",
    "        )\n",
    "        return response.text \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating response: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b4fe8358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(context: str, query: str) -> str:\n",
    "    prompt = prompt = (\n",
    "    \"Użyj poniższego kontekstu, aby odpowiedzieć na pytanie.\\n\"\n",
    "    \"Jeśli kontekst nie zawiera odpowiedzi, powiedz o tym wprost.\\n\\n\"\n",
    "    f\"KONTEKST:\\n{context}\\n\\n\"\n",
    "    f\"PYTANIE:\\n{query}\\n\\n\"\n",
    "    \"ODPOWIEDŹ:\"\n",
    "    )\n",
    "    return prompt\n",
    "    \n",
    "\n",
    "def rag(model, query: str) -> str:\n",
    "    embedded_query = model.encode(query).tolist()\n",
    "\n",
    "\n",
    "    result = milvus_client.search(\n",
    "    collection_name=\"rag_texts_and_embeddings\",\n",
    "    data=[embedded_query],\n",
    "    limit=1,\n",
    "    search_params={\"metric_type\": \"L2\"},\n",
    "    output_fields=[\"text\"]\n",
    "    )\n",
    "\n",
    "    context = result[0][0][\"entity\"][\"text\"]\n",
    "\n",
    "    prompt = build_prompt(context, query)\n",
    "\n",
    "    return generate_response(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7f6f5b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sztuczna inteligencja (AI) to obszar informatyki, który skupia się na tworzeniu programów komputerowych zdolnych do wykonywania zadań, które wymagają ludzkiej inteligencji.\n"
     ]
    }
   ],
   "source": [
    "question = \"Czym jest sztuczna inteligencja?\"\n",
    "answer = rag(model, question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "22111722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kontekst nie podaje informacji o najpopularniejszych modelach AI.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"Jakie są najpopularniejsze modele AI\"\n",
    "answer = rag(model, question)\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab_4MLProject (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
